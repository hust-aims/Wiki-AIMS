The Tail at Scale   
搜索响应时间在100ms内用户才会感到流畅与自然，另外增强现实设备也需要流畅的搜索服务。随着系统规模的扩大，长尾延迟对于搜索服务提供者越来越有挑战性。   
响应时间变化原因:   
1. 共享资源的争用;   
2. 后台驻留程序;   
3. 全局资源的共享;   
4. 维护活动;   
5. 排队阻塞;   
6. 硬件影响;(CPU的能量限制, 固态盘的垃圾回收, 设备节能模式等)   

随着系统规模的增大，单个组件的延迟变化会在服务层放大。比如一台服务器响应延迟是10ms, 只有1％的请求会超过1s, 但是如果一个请求需要使用100台这样的服务器并行完成，那么63％的请求会超过1s。如果有一台服务器0.01%的请求会超过1s, 但是如果一个请求需要使用2000台这样的服务器并行完成，那么18％的请求会超过1s。另外完成100%请求的延迟时间(140ms)是完成95%请求 (70ms)延迟的2倍。
 
## 减少组件的变化(根本上减少延迟)
### 1. 区分服务等级和使用高层队列
不同的服务等级响应时间不同；在顶层设置队列，让底层队列尽可能流的快。
### 2. 减少head-of-line阻塞[1]
将长时间请求切割成多个短的IO请求交错执行。
### 3. 管理后台活动和同步分解
合理调度后台程序，减少资源的争用对服务的影响。尽量将后台活动安排在总体负载较低时进行处理，而不是周期性处理后台的活动。
 
## 与延迟变化共生(减少延迟的影响)
### 短期请求内的适应
#### 次级请求[2]
向所有副本发送请求，谁先响应就用谁的。如果第一次请求没有在95%的平均延迟时间内响应，就发送第二个请求。   
？？？有个问题就是如果是网络问题，重试好像也没法解决吧。
#### 绑定请求[3]
每个请求携带状态信息，任意响应的请求会给其他对应请求发送终止信息。主要是为了快速终止其他对应请求，降低资源的损耗。
 
### 长期跨请求的适应
#### micro-partitions
每台机器上平均20个分区，动态分配任务，只需要调度细粒度的分区，在机器发生故障时多机器能并行承担起故障机器上的任务。
#### selective replication
是微分区的扩展策略，能够对热点数据产生多个副本，分散热点负载而不是移动分区。
#### latency-induced probation
将特别慢的机器进行隔离，同样需要发送影子请求测试是否恢复正常，一旦正常重新加入集群。
 
## 大规模信息检索系统
### 足够好
追求足够好的响应而不是最好的；同时允许跳过一些非必需的子系统来提高响应，比如广告与拼写纠正系统响应不及时，网络搜索可以跳过它们。
### 金丝雀请求
为了避免服务挂了或Dos攻击，先发送1～2个请求到叶子节点服务器，如果正常再发送请求到剩余叶子节点。
 
## 硬件趋势及影响
随着异构硬件的制造，利用软件技术容忍尾延迟会变得更加重要。数据中心的高对分带宽网络和网络接口的优化能减少信息传递开销(eg RDMA)。
   
[1]head-of-line阻塞:   
又称头部阻塞, 比如说你行驶在单线道想右拐，前方右拐道空闲但是你前面有车导致你无法拐道。   
[2]hedged requests:   
次级请求是指第一次请求没有在完成95%请求的平均延迟时间内返回的情况下，发送的第二个请求。   
[3]Tied requests:   
绑定请求是指能够携带扩服务器交互状态信息的请求，一旦请求响应即可给其他请求副本发终止信息。

